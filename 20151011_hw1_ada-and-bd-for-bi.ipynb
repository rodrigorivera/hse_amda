{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 1 Part 2\n",
    "Rodrigo Rivera - 11/10/2015\n",
    "\n",
    "Text mining. \n",
    "Input data: collection of text documents / tweets and etc.\n",
    "Main objective: find the TF.IDF for each word\n",
    "\n",
    "1.\tDownload (find) or use the proposed data collection (see the attachment) for text mining.\n",
    "We will use as a data collection for text mining a collection of works from Oscar Wilde (17 in total)\n",
    "2.\tPerform the data preparation (removing stop words, punctuation, stemming and etc.) + term document matrix\n",
    "3.\tCount the TF.IDF measure for each term (word). You can use any TF and IDF form you want (https://en.wikipedia.org/wiki/Tf%E2%80%93idf) \n",
    "4.\tMake a report (.doc file with the steps of work, script and comments)\n",
    "\n",
    "Steps performed:\n",
    "0. Import the TextAnalysis library into the Julia environment\n",
    "1. Load the directory with the Oscar Wilde texts as a corpus into Julia as a FileDocument\n",
    "2. Convert the FileDocument to StringDocument so we can edit it and preprocess it. (Note: This will load the file in memory as a string and therefore it only works for moderately sized corpus)\n",
    "3. Display in screen text statistics to quickly verify that it was loaded\n",
    "4. Perform preprocessing removing numbers, punctuation, stop words, articles, etc\n",
    "5. Use TF.IDF\n",
    "6. Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using TextAnalysis\n",
    "using DataFrames\n",
    "import Base: convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create 2 corpus based on the same set of files, one that we will leave untouched for comparison purposes and another one that will be manipulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crps = DirectoryCorpus(\"wilde\")\n",
    "standardize!(crps, StringDocument)\n",
    "\n",
    "crps2 = DirectoryCorpus(\"wilde\")\n",
    "standardize!(crps2, StringDocument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A Corpus"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: MethodError: `text` has no method matching text(::TextAnalysis.Corpus)\nwhile loading In[16], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: MethodError: `text` has no method matching text(::TextAnalysis.Corpus)\nwhile loading In[16], in expression starting on line 1",
      ""
     ]
    }
   ],
   "source": [
    "text(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: MethodError: `zero` has no method matching zero(::Type{Char})\nwhile loading In[17], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: MethodError: `zero` has no method matching zero(::Type{Char})\nwhile loading In[17], in expression starting on line 1",
      "",
      " in remove_corrupt_utf8 at /home/ubuntu/.julia/v0.4/TextAnalysis/src/preprocessing.jl:46",
      " in remove_corrupt_utf8! at /home/ubuntu/.julia/v0.4/TextAnalysis/src/preprocessing.jl:58",
      " in remove_corrupt_utf8! at /home/ubuntu/.julia/v0.4/TextAnalysis/src/preprocessing.jl:83"
     ]
    }
   ],
   "source": [
    "remove_corrupt_utf8!(crps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets verify our lexicon and our inverse index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17878-element Array{Tuple{Int64,UTF8String},1}:\n",
       " (5616,\"the\")     \n",
       " (3061,\"of\")      \n",
       " (2873,\"and\")     \n",
       " (2438,\"to\")      \n",
       " (1996,\"a\")       \n",
       " (1627,\"I\")       \n",
       " (1524,\"in\")      \n",
       " (1448,\"that\")    \n",
       " (1203,\"his\")     \n",
       " (1140,\"was\")     \n",
       " (1133,\"he\")      \n",
       " (1073,\"is\")      \n",
       " (1012,\"with\")    \n",
       " ⋮                \n",
       " (1,\"\\\"And...\")   \n",
       " (1,\"\\\"Always!\")  \n",
       " (1,\"\\\"Always\")   \n",
       " (1,\"\\\"Alas!\")    \n",
       " (1,\"\\\"Alan!\")    \n",
       " (1,\"\\\"Alan\")     \n",
       " (1,\"\\\"Aeschylos\")\n",
       " (1,\"\\\"Acting!\")  \n",
       " (1,\"\\\"About\")    \n",
       " (1,\"\\\"'what\")    \n",
       " (1,\"\\\"'a\")       \n",
       " (1,\"\\\"'Tis\")     "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_lexicon!(crps)\n",
    "update_lexicon!(crps2)\n",
    "dict_lexico = lexicon(crps)\n",
    "sort(collect(zip(values(dict_lexico),keys(dict_lexico))), rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{UTF8String,Array{Int64,1}} with 17878 entries:\n",
       "  \"conservatory,\"  => [13]\n",
       "  \"bear.\\\"\"        => [13]\n",
       "  \"olive-green\"    => [13]\n",
       "  \"frowning\"       => [13,14]\n",
       "  \"Thomas.\\\"\"      => [13]\n",
       "  \"leadenness,\"    => [2]\n",
       "  \"spell,\"         => [13,14]\n",
       "  \"rises\"          => [11]\n",
       "  \"Raced\"          => [3]\n",
       "  \"gathered\"       => [10]\n",
       "  \"lovers\"         => [2,3,5,12,13,16,17]\n",
       "  \"little,\"        => [1]\n",
       "  \"Letters.\\\"\"     => [13]\n",
       "  \"ture\"           => [13]\n",
       "  \"dear,\"          => [13]\n",
       "  \"caught\"         => [1,3,11,13,14,15]\n",
       "  \"stress\"         => [3]\n",
       "  \"ideas,\"         => [13]\n",
       "  \"title-page\"     => [13]\n",
       "  \"obey\"           => [3]\n",
       "  \"methods\"        => [13]\n",
       "  \"women.\\\"\"       => [13]\n",
       "  \"jealous?\\\"\"     => [13]\n",
       "  \"wept:\"          => [1]\n",
       "  \"almond-scented\" => [6]\n",
       "  ⋮                => ⋮"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_inverse_index!(crps)\n",
    "update_inverse_index!(crps2)\n",
    "inverse_index(crps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the preprocessing and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare!(crps, strip_punctuation)\n",
    "prepare!(crps, strip_numbers)\n",
    "prepare!(crps, strip_case)\n",
    "prepare!(crps, strip_stopwords)\n",
    "prepare!(crps, strip_articles)\n",
    "prepare!(crps, strip_indefinite_articles)\n",
    "prepare!(crps, strip_prepositions)\n",
    "prepare!(crps, strip_pronouns)\n",
    "stem!(crps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify the sizes of our lexicons now that we have preprocessed our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7447-element Array{Tuple{Int64,UTF8String},1}:\n",
       " (2845,\"\\\"\")      \n",
       " (390,\"dorian\")   \n",
       " (304,\"love\")     \n",
       " (290,\"look\")     \n",
       " (277,\"lord\")     \n",
       " (270,\"life\")     \n",
       " (237,\"henri\")    \n",
       " (225,\"gray\")     \n",
       " (205,\"-\")        \n",
       " (189,\"hand\")     \n",
       " (184,\"eye\")      \n",
       " (183,\"day\")      \n",
       " (165,\"littl\")    \n",
       " ⋮                \n",
       " (1,\"\\\"clericali\")\n",
       " (1,\"\\\"christ\")   \n",
       " (1,\"\\\"charm\")    \n",
       " (1,\"\\\"caress\")   \n",
       " (1,\"\\\"bring\")    \n",
       " (1,\"\\\"awak\")     \n",
       " (1,\"\\\"appreci\")  \n",
       " (1,\"\\\"ala\")      \n",
       " (1,\"\\\"aeschylo\") \n",
       " (1,\"\\\"act\")      \n",
       " (1,\"\\\"-\")        \n",
       " (1,\"\\\"'tis\")     "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_lexicon!(crps)\n",
    "dict_lexico = lexicon(crps)\n",
    "sort(collect(zip(values(dict_lexico),keys(dict_lexico))), rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that after the preprocessing and stemming our most popular words changed drastically, before they were mostly articles and now the most common word is \"Dorian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{UTF8String,Array{Int64,1}} with 7447 entries:\n",
       "  \"ont\"         => [13]\n",
       "  \"enjoy\"       => [13]\n",
       "  \"fight\"       => [1,2,4,13,14]\n",
       "  \"exult\"       => [9]\n",
       "  \"requiescat\"  => [15]\n",
       "  \"olive-green\" => [13]\n",
       "  \"faun\"        => [2,3,12,13,17]\n",
       "  \"wintri\"      => [11,14]\n",
       "  \"\\\"human\"     => [13]\n",
       "  \"sleepless\"   => [12,13]\n",
       "  \"favor\"       => [13]\n",
       "  \"gout\"        => [1]\n",
       "  \"purple-\"     => [13]\n",
       "  \"cromwel\"     => [4,9]\n",
       "  \"curv\"        => [8,13,15,16]\n",
       "  \"star\"        => [1,2,3,4,6,7,8,9,11,12,13,14,15,16]\n",
       "  \"worship\"     => [2,3,11,13]\n",
       "  \"prick\"       => [2]\n",
       "  \"strand\"      => [3,4,9,11,12]\n",
       "  \"rejoin\"      => [13]\n",
       "  \"reform\"      => [13]\n",
       "  \"plan\"        => [1,13]\n",
       "  \"entreat\"     => [13]\n",
       "  \"perspir\"     => [13]\n",
       "  \"clue\"        => [13]\n",
       "  ⋮             => ⋮"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_inverse_index!(crps)\n",
    "inverse_index(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17878"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_size(crps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7447"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_size(crps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing and stemming, we see that our corpus has, so many entries in % compared to the original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41654547488533394"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_size(crps)/lexicon_size(crps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A DocumentTermMatrix"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_lexicon!(crps)\n",
    "m = DocumentTermMatrix(crps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a sparse document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17x7447 sparse matrix with 15974 Int64 entries:\n",
       "\t[1   ,    1]  =  5\n",
       "\t[3   ,    1]  =  29\n",
       "\t[6   ,    1]  =  4\n",
       "\t[9   ,    1]  =  1\n",
       "\t[11  ,    1]  =  3\n",
       "\t[13  ,    1]  =  2796\n",
       "\t[15  ,    1]  =  7\n",
       "\t[13  ,    2]  =  4\n",
       "\t[9   ,    3]  =  1\n",
       "\t[13  ,    4]  =  1\n",
       "\t⋮\n",
       "\t[9   , 7441]  =  2\n",
       "\t[12  , 7441]  =  1\n",
       "\t[13  , 7441]  =  37\n",
       "\t[14  , 7441]  =  2\n",
       "\t[17  , 7441]  =  1\n",
       "\t[13  , 7442]  =  2\n",
       "\t[6   , 7443]  =  1\n",
       "\t[13  , 7444]  =  1\n",
       "\t[13  , 7445]  =  1\n",
       "\t[13  , 7446]  =  1\n",
       "\t[3   , 7447]  =  1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix = dtm(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17x7447 Array{Int64,2}:\n",
       "    5  0  0  0  0  0   0  0  0  0  0  …  0  0  0  0  0   0  0  0  0  0  0  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0     3  3  0  0  0   1  0  0  0  0  0  0\n",
       "   29  0  0  0  0  0   0  0  0  0  0     1  0  0  0  0   1  0  0  0  0  0  1\n",
       "    0  0  0  0  0  0   0  0  0  0  0     0  0  0  0  0   0  0  0  0  0  0  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0     0  0  0  0  0   3  0  0  0  0  0  0\n",
       "    4  0  0  0  0  1   0  0  0  0  0  …  1  0  0  0  0   0  0  1  0  0  0  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0     0  0  0  0  0   2  0  0  0  0  0  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0     3  1  0  0  0   0  0  0  0  0  0  0\n",
       "    1  0  1  0  0  0   0  0  0  0  0     1  0  1  0  1   2  0  0  0  0  0  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0     0  0  0  0  0   0  0  0  0  0  0  0\n",
       "    3  0  0  0  0  0   0  0  0  0  0  …  0  0  0  0  0   0  0  0  0  0  0  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0     1  1  0  0  0   1  0  0  0  0  0  0\n",
       " 2796  4  0  1  1  0  22  0  6  2  1     0  0  0  1  0  37  2  0  1  1  1  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0     3  0  0  0  0   2  0  0  0  0  0  0\n",
       "    7  0  0  0  0  0   0  1  0  0  0     2  0  0  0  0   0  0  0  0  0  0  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0  …  0  0  0  0  0   0  0  0  0  0  0  0\n",
       "    0  0  0  0  0  0   0  0  0  0  0     0  0  0  0  0   1  0  0  0  0  0  0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_matrix = dtm(m, :dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do TF-IDF with our Document Term Matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17x7447 Array{Float64,2}:\n",
       " 0.00267582   0.0          0.0         …  0.0         0.0         0.0       \n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       \n",
       " 0.00936723   0.0          0.0            0.0         0.0         0.00103138\n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       \n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       \n",
       " 0.00389168   0.0          0.0         …  0.0         0.0         0.0       \n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       \n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       \n",
       " 0.000513783  0.0          0.00164054     0.0         0.0         0.0       \n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       \n",
       " 0.00275275   0.0          0.0         …  0.0         0.0         0.0       \n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       \n",
       " 0.0820349    0.000374739  0.0            9.36847e-5  9.36847e-5  0.0       \n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       \n",
       " 0.00459743   0.0          0.0            0.0         0.0         0.0       \n",
       " 0.0          0.0          0.0         …  0.0         0.0         0.0       \n",
       " 0.0          0.0          0.0            0.0         0.0         0.0       "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_tfidf = tf_idf(dense_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1x7447 Array{Int64,2}:\n",
       " 5  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtv(crps[1], lexicon(crps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.1",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
