{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "\n",
    "## Rodrigo Rivera\n",
    "\n",
    "### Shingling and minhashing\n",
    "\n",
    "1. Take the collection of documents\n",
    "2. Do shingling with k1=4\n",
    "2.1. singling function: Arguments are document, k. Output must be a list of shingles, no duplicates. Hashing can be excluded\n",
    "2.2. Create the hash function that converts string to integer shingles\n",
    "3. Total: Output matrix (rows shingles, columns documents)\n",
    "\n",
    "### Clustering\n",
    "1. Draw the dendogram for the matrix\n",
    "2. Make the conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import binascii\n",
    "from bisect import bisect_right\n",
    "from heapq import heappop, heappush\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wilde-rosa-610.txt',\n",
       " 'wilde-burden-612.txt',\n",
       " 'wilde-ballad-611.txt',\n",
       " 'wilde-charmides-601.txt',\n",
       " 'wilde-garden-614.txt',\n",
       " 'wilde-impressions-606.txt',\n",
       " 'wilde-panthea-608.txt',\n",
       " 'wilde-humanitad-605.txt',\n",
       " 'wilde-miscellaneous-607.txt',\n",
       " 'wilde-picture-615.txt',\n",
       " 'wilde-flowers-604.txt',\n",
       " 'wilde-fourth-613.txt',\n",
       " 'wilde-eleutheria-602.txt',\n",
       " 'wilde-ravenna-609.txt',\n",
       " 'wilde-sphinx-616.txt',\n",
       " 'wilde-wind-617.txt',\n",
       " 'wilde-flower-603.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = \"wilde\"\n",
    "only_files_path = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "only_files_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#               Convert Documents To Sets of Shingles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shingling articles...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e392a7e19866>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdocNames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtotalShingles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "print \"Shingling articles...\"\n",
    "\n",
    "# The current shingle ID value to assign to the next new shingle we \n",
    "# encounter. When a shingle gets added to the dictionary, we'll increment this\n",
    "# value.\n",
    "curShingleID = 0\n",
    "\n",
    "# Create a dictionary of the articles, mapping the article identifier (e.g., \n",
    "# \"t8470\") to the list of shingle IDs that appear in the document.\n",
    "docsAsShingleSets = {};\n",
    "\n",
    "docNames = []\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "totalShingles = 0\n",
    "num_docs = len(only_files_path)\n",
    "\n",
    "for file in only_files_path:\n",
    "    full_file_path = dir_path+'/'+file\n",
    "    print file\n",
    "    f = open(full_file_path,\"r\")\n",
    "    # Read all of the words (they are all on one line) and split them by white space.\n",
    "    words\n",
    "    for line in f.readlines():\n",
    "        words = line \n",
    "    # Retrieve the article ID, which is the first word on the line.  \n",
    "    docID = str(file)\n",
    "    # Maintain a list of all document IDs.  \n",
    "    docNames.append(docID)\n",
    "    #del words[0]\n",
    "    # 'shinglesInDoc' will hold all of the unique shingle IDs present in the \n",
    "    # current document. If a shingle ID occurs multiple times in the document,\n",
    "    # it will only appear once in the set (this is a property of Python sets).\n",
    "    shinglesInDoc = set()\n",
    "    # For each word in the document...\n",
    "    for index in range(0, len(words) - 3):\n",
    "        # Construct the shingle text by combining four words together.\n",
    "        shingle = words[index] + \" \" + words[index + 1] + \" \" + words[index + 2]+ \" \" + words[index + 3]\n",
    "        # Hash the shingle to a 32-bit integer.\n",
    "        crc = binascii.crc32(shingle) & 0xffffffff\n",
    "        # Add the hash value to the list of shingles for the current document. \n",
    "        # Note that set objects will only add the value to the set if the set \n",
    "        # doesn't already contain it. \n",
    "        shinglesInDoc.add(crc)\n",
    "        # Store the completed list of shingles for this document in the dictionary.\n",
    "        docsAsShingleSets[docID] = shinglesInDoc\n",
    "    # Close the data file.  \n",
    "    f.close()        \n",
    "\n",
    "#Count the number of shingles across all documents.\n",
    "totalShingles = totalShingles + (len(words) - 3)\n",
    "\n",
    "# Report how long shingling took.\n",
    "print '\\nShingling ' + str(num_docs) + ' docs took %.2f sec.' % (time.time() - t0)\n",
    " \n",
    "print '\\nAverage shingles per doc: %.2f' % (totalShingles / num_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                     Define Triangle Matrices\n",
    "\n",
    "Define virtual Triangle matrices to hold the similarity values. For storing similarities between pairs, we only need roughly half the elements of a full matrix. Using a triangle matrix requires less than half the memory of a full matrix, and can protect the programmer from inadvertently accessing one of the empty/invalid cells of a full matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the number of elements needed in our triangle matrix\n",
    "num_docs = len(only_files_path)\n",
    "numElems = int(num_docs * (num_docs - 1) / 2)\n",
    "\n",
    "# Initialize two empty lists to store the similarity values. \n",
    "# 'JSim' will be for the actual Jaccard Similarity values. \n",
    "# 'estJSim' will be for the estimated Jaccard Similarities found by comparing\n",
    "# the MinHash signatures.\n",
    "JSim = [0 for x in range(numElems)]\n",
    "estJSim = [0 for x in range(numElems)]\n",
    "\n",
    "# Define a function to map a 2D matrix coordinate into a 1D index.\n",
    "def getTriangleIndex(i, j):\n",
    "  # If i == j that's an error.\n",
    "  if i == j:\n",
    "    sys.stderr.write(\"Can't access triangle matrix with i == j\")\n",
    "    sys.exit(1)\n",
    "  # If j < i just swap the values.\n",
    "  if j < i:\n",
    "    temp = i\n",
    "    i = j\n",
    "    j = temp\n",
    "  \n",
    "  # Calculate the index within the triangular array.\n",
    "  # This fancy indexing scheme is taken from pg. 211 of:\n",
    "  # http://infolab.stanford.edu/~ullman/mmds/ch6.pdf\n",
    "  # But I adapted it for a 0-based index.\n",
    "  # Note: The division by two should not truncate, it\n",
    "  #       needs to be a float. \n",
    "  k = int(i * (num_docs - (i + 1) / 2.0) + j - i) - 1\n",
    "  \n",
    "  return k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                 Calculate Jaccard Similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Jaccard Similarities...\n",
      "  (0 / 17)\n",
      "\n",
      "Calculating all Jaccard Similarities took 0.00sec\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Jaccard similarities gets really slow for large numbers\n",
    "# of documents.\n",
    "if len(only_files_path) <= 2500:\n",
    "#if True:\n",
    "    print \"\\nCalculating Jaccard Similarities...\"\n",
    "\n",
    "    # Time the calculation.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # For every document pair...\n",
    "    for i in range(0, len(only_files_path)):\n",
    "      \n",
    "      # Print progress every 100 documents.\n",
    "      if (i % 100) == 0:\n",
    "        print \"  (\" + str(i) + \" / \" + str(len(only_files_path)) + \")\"\n",
    "\n",
    "      # Retrieve the set of shingles for document i.\n",
    "      s1 = docsAsShingleSets[docNames[i]]\n",
    "      \n",
    "      for j in range(i + 1, len(only_files_path)):\n",
    "        # Retrieve the set of shingles for document j.\n",
    "        s2 = docsAsShingleSets[docNames[j]]\n",
    "        \n",
    "        # Calculate and store the actual Jaccard similarity.\n",
    "        JSim[getTriangleIndex(i, j)] = (len(s1.intersection(s2)) / len(s1.union(s2)))    \n",
    "\n",
    "    # Calculate the elapsed time (in seconds)\n",
    "    elapsed = (time.time() - t0)\n",
    "        \n",
    "    print \"\\nCalculating all Jaccard Similarities took %.2fsec\" % elapsed\n",
    "\n",
    "# Delete the Jaccard Similarities, since it's a pretty big matrix.    \n",
    "del JSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                 Generate MinHash Signatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating random hash functions...\n",
      "\n",
      "Generating MinHash signatures for all documents...\n",
      "\n",
      "Generating MinHash signatures took 0.00sec\n"
     ]
    }
   ],
   "source": [
    "# This is the number of components in the resulting MinHash signatures.\n",
    "# Correspondingly, it is also the number of random hash functions that\n",
    "# we will need in order to calculate the MinHash.\n",
    "numHashes = 10;\n",
    "\n",
    "# Time this step.\n",
    "t0 = time.time()\n",
    "\n",
    "print '\\nGenerating random hash functions...'\n",
    "\n",
    "# Record the maximum shingle ID that we assigned.\n",
    "maxShingleID = 2**32-1\n",
    "\n",
    "# We need the next largest prime number above 'maxShingleID'.\n",
    "# I looked this value up here: \n",
    "# http://compoasso.free.fr/primelistweb/page/prime/liste_online_en.php\n",
    "nextPrime = 4294967311\n",
    "\n",
    "\n",
    "# Our random hash function will take the form of:\n",
    "#   h(x) = (a*x + b) % c\n",
    "# Where 'x' is the input value, 'a' and 'b' are random coefficients, and 'c' is\n",
    "# a prime number just greater than maxShingleID.\n",
    "\n",
    "# Generate a list of 'k' random coefficients for the random hash functions,\n",
    "# while ensuring that the same value does not appear multiple times in the \n",
    "# list.\n",
    "def pickRandomCoeffs(k):\n",
    "  # Create a list of 'k' random values.\n",
    "  randList = []\n",
    "  \n",
    "  while k > 0:\n",
    "    # Get a random shingle ID.\n",
    "    randIndex = random.randint(0, maxShingleID) \n",
    "  \n",
    "    # Ensure that each random number is unique.\n",
    "    while randIndex in randList:\n",
    "      randIndex = random.randint(0, maxShingleID) \n",
    "    \n",
    "    # Add the random number to the list.\n",
    "    randList.append(randIndex)\n",
    "    k = k - 1\n",
    "    \n",
    "  return randList\n",
    "\n",
    "# For each of the 'numHashes' hash functions, generate a different coefficient 'a' and 'b'.   \n",
    "coeffA = pickRandomCoeffs(numHashes)\n",
    "coeffB = pickRandomCoeffs(numHashes)\n",
    "\n",
    "print '\\nGenerating MinHash signatures for all documents...'\n",
    "\n",
    "# List of documents represented as signature vectors\n",
    "signatures = []\n",
    "\n",
    "# Rather than generating a random permutation of all possible shingles, \n",
    "# we'll just hash the IDs of the shingles that are *actually in the document*,\n",
    "# then take the lowest resulting hash code value. This corresponds to the index \n",
    "# of the first shingle that you would have encountered in the random order.\n",
    "\n",
    "# For each document...\n",
    "for docID in only_files_path:\n",
    "  \n",
    "  # Get the shingle set for this document.\n",
    "  shingleIDSet = docsAsShingleSets[docID]\n",
    "  \n",
    "  # The resulting minhash signature for this document. \n",
    "  signature = []\n",
    "  \n",
    "  # For each of the random hash functions...\n",
    "  for i in range(0, numHashes):\n",
    "    \n",
    "    # For each of the shingles actually in the document, calculate its hash code\n",
    "    # using hash function 'i'. \n",
    "    \n",
    "    # Track the lowest hash ID seen. Initialize 'minHashCode' to be greater than\n",
    "    # the maximum possible value output by the hash.\n",
    "    minHashCode = nextPrime + 1\n",
    "    \n",
    "    # For each shingle in the document...\n",
    "    for shingleID in shingleIDSet:\n",
    "      # Evaluate the hash function.\n",
    "      hashCode = (coeffA[i] * shingleID + coeffB[i]) % nextPrime \n",
    "      \n",
    "      # Track the lowest hash code seen.\n",
    "      if hashCode < minHashCode:\n",
    "        minHashCode = hashCode\n",
    "\n",
    "    # Add the smallest hash code value as component number 'i' of the signature.\n",
    "    signature.append(minHashCode)\n",
    "  \n",
    "  # Store the MinHash signature for this document.\n",
    "  signatures.append(signature)\n",
    "\n",
    "# Calculate the elapsed time (in seconds)\n",
    "elapsed = (time.time() - t0)\n",
    "        \n",
    "print \"\\nGenerating MinHash signatures took %.2fsec\" % elapsed  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                     Compare All Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing all signatures...\n",
      "\n",
      "Comparing MinHash signatures took 0.13sec\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "print '\\nComparing all signatures...'  \n",
    "  \n",
    "# Creates a N x N matrix initialized to 0.\n",
    "\n",
    "# Time this step.\n",
    "t0 = time.time()\n",
    "\n",
    "# For each of the test documents...\n",
    "for i in range(0, len(only_files_path)):\n",
    "  # Get the MinHash signature for document i.\n",
    "  signature1 = signatures[i]\n",
    "    \n",
    "  # For each of the other test documents...\n",
    "  for j in range(i + 1, len(only_files_path)):\n",
    "    \n",
    "    # Get the MinHash signature for document j.\n",
    "    signature2 = signatures[j]\n",
    "    \n",
    "    count = 0\n",
    "    # Count the number of positions in the minhash signature which are equal.\n",
    "    for k in range(0, numHashes):\n",
    "      count = count + (signature1[k] == signature2[k])\n",
    "    \n",
    "    # Record the percentage of positions which matched.    \n",
    "    estJSim[getTriangleIndex(i, j)] = (count / numHashes)\n",
    "\n",
    "# Calculate the elapsed time (in seconds)\n",
    "elapsed = (time.time() - t0)\n",
    "        \n",
    "print \"\\nComparing MinHash signatures took %.2fsec\" % elapsed  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                   Display Similar Document Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of Document Pairs with J(d1,d2) more than 0.6\n",
      "Values shown are the estimated Jaccard similarity and the actual Jaccard similarity.\n",
      "\n",
      "                                          Estimated Jaccard   VS Actual Jaccard\n",
      "  wilde-rosa-610.txt --> wilde-burden-612.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-charmides-601.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-garden-614.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-impressions-606.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-panthea-608.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-humanitad-605.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-picture-615.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-flowers-604.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-rosa-610.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-charmides-601.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-garden-614.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-impressions-606.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-panthea-608.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-humanitad-605.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-picture-615.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-flowers-604.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-burden-612.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-garden-614.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-impressions-606.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-panthea-608.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-humanitad-605.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-picture-615.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-flowers-604.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-charmides-601.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-impressions-606.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-panthea-608.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-humanitad-605.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-picture-615.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-flowers-604.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-garden-614.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-impressions-606.txt --> wilde-panthea-608.txt   1.00     1.00\n",
      "  wilde-impressions-606.txt --> wilde-humanitad-605.txt   1.00     1.00\n",
      "  wilde-impressions-606.txt --> wilde-picture-615.txt   1.00     1.00\n",
      "  wilde-impressions-606.txt --> wilde-flowers-604.txt   1.00     1.00\n",
      "  wilde-impressions-606.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-impressions-606.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-impressions-606.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-impressions-606.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-panthea-608.txt --> wilde-humanitad-605.txt   1.00     1.00\n",
      "  wilde-panthea-608.txt --> wilde-picture-615.txt   1.00     1.00\n",
      "  wilde-panthea-608.txt --> wilde-flowers-604.txt   1.00     1.00\n",
      "  wilde-panthea-608.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-panthea-608.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-panthea-608.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-panthea-608.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-humanitad-605.txt --> wilde-picture-615.txt   1.00     1.00\n",
      "  wilde-humanitad-605.txt --> wilde-flowers-604.txt   1.00     1.00\n",
      "  wilde-humanitad-605.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-humanitad-605.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-humanitad-605.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-humanitad-605.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-picture-615.txt --> wilde-flowers-604.txt   1.00     1.00\n",
      "  wilde-picture-615.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-picture-615.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-picture-615.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-picture-615.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-flowers-604.txt --> wilde-fourth-613.txt   1.00     1.00\n",
      "  wilde-flowers-604.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-flowers-604.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-flowers-604.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-fourth-613.txt --> wilde-eleutheria-602.txt   1.00     1.00\n",
      "  wilde-fourth-613.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-fourth-613.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-eleutheria-602.txt --> wilde-wind-617.txt   1.00     1.00\n",
      "  wilde-eleutheria-602.txt --> wilde-flower-603.txt   1.00     1.00\n",
      "  wilde-wind-617.txt --> wilde-flower-603.txt   1.00     1.00\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.6  \n",
    "print \"\\nList of Document Pairs with J(d1,d2) more than\", threshold\n",
    "print \"Values shown are the estimated Jaccard similarity and the actual Jaccard similarity.\\n\"\n",
    "print \"                                          Estimated Jaccard   VS Actual Jaccard\"\n",
    "\n",
    "# For each of the document pairs...\n",
    "for i in range(0, len(only_files_path)):  \n",
    "  for j in range(i + 1, len(only_files_path)):\n",
    "    # Retrieve the estimated similarity value for this pair.\n",
    "    estJ = estJSim[getTriangleIndex(i, j)]\n",
    "    \n",
    "    # If the similarity is above the threshold...\n",
    "    if estJ > threshold:\n",
    "    \n",
    "      # Calculate the actual Jaccard similarity for validation.\n",
    "      s1 = docsAsShingleSets[docNames[i]]\n",
    "      s2 = docsAsShingleSets[docNames[j]]\n",
    "      J = (len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "      \n",
    "      # Print out the match and similarity values with pretty spacing.\n",
    "      print \"  %5s --> %5s   %.2f     %.2f\" % (docNames[i], docNames[j], estJ, J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                   Display Different Document Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of Document Pairs with J(d1,d2) less than 0.3\n",
      "Values shown are the estimated Jaccard similarity and the actual Jaccard similarity.\n",
      "\n",
      "                                          Estimated Jaccard   VS Actual Jaccard\n",
      "  wilde-rosa-610.txt --> wilde-miscellaneous-607.txt   0.20     0.33\n",
      "  wilde-rosa-610.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-burden-612.txt --> wilde-miscellaneous-607.txt   0.20     0.33\n",
      "  wilde-burden-612.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-ballad-611.txt --> wilde-miscellaneous-607.txt   0.20     0.33\n",
      "  wilde-charmides-601.txt --> wilde-miscellaneous-607.txt   0.20     0.33\n",
      "  wilde-charmides-601.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-garden-614.txt --> wilde-miscellaneous-607.txt   0.20     0.33\n",
      "  wilde-garden-614.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-impressions-606.txt --> wilde-miscellaneous-607.txt   0.20     0.33\n",
      "  wilde-impressions-606.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-panthea-608.txt --> wilde-miscellaneous-607.txt   0.20     0.33\n",
      "  wilde-panthea-608.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-humanitad-605.txt --> wilde-miscellaneous-607.txt   0.20     0.33\n",
      "  wilde-humanitad-605.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-miscellaneous-607.txt --> wilde-picture-615.txt   0.20     0.33\n",
      "  wilde-miscellaneous-607.txt --> wilde-flowers-604.txt   0.20     0.33\n",
      "  wilde-miscellaneous-607.txt --> wilde-fourth-613.txt   0.20     0.33\n",
      "  wilde-miscellaneous-607.txt --> wilde-eleutheria-602.txt   0.20     0.33\n",
      "  wilde-miscellaneous-607.txt --> wilde-wind-617.txt   0.20     0.33\n",
      "  wilde-miscellaneous-607.txt --> wilde-flower-603.txt   0.20     0.33\n",
      "  wilde-picture-615.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-flowers-604.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-fourth-613.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-eleutheria-602.txt --> wilde-sphinx-616.txt   0.20     0.33\n",
      "  wilde-sphinx-616.txt --> wilde-wind-617.txt   0.20     0.33\n",
      "  wilde-sphinx-616.txt --> wilde-flower-603.txt   0.20     0.33\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "print \"\\nList of Document Pairs with J(d1,d2) less than\", threshold\n",
    "print \"Values shown are the estimated Jaccard similarity and the actual Jaccard similarity.\\n\"\n",
    "print \"                                          Estimated Jaccard   VS Actual Jaccard\"\n",
    "\n",
    "# For each of the document pairs...\n",
    "for i in range(0, len(only_files_path)):  \n",
    "  for j in range(i + 1, len(only_files_path)):\n",
    "    # Retrieve the estimated similarity value for this pair.\n",
    "    estJ = estJSim[getTriangleIndex(i, j)]\n",
    "    \n",
    "    # If the similarity is above the threshold...\n",
    "    if estJ < threshold:\n",
    "    \n",
    "      # Calculate the actual Jaccard similarity for validation.\n",
    "      s1 = docsAsShingleSets[docNames[i]]\n",
    "      s2 = docsAsShingleSets[docNames[j]]\n",
    "      J = (len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "      \n",
    "      # Print out the match and similarity values with pretty spacing.\n",
    "      print \"  %5s --> %5s   %.2f     %.2f\" % (docNames[i], docNames[j], estJ, J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a lot of files have high similarities while at the same time some others are not very similar. In the previous homework we could see how the texts from Oscar Wilde use frequently the same type of words and our shingles are very small. We can expect therefore a lot of repetition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, with these 2 visualisations, we do not need a dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
